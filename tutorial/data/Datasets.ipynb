{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Importing Datasets into MuSE\n",
    "\n",
    "Currently, MuSE supports the following data formats:\n",
    "- CSV\n",
    "- Parquet\n",
    "- Directory of text files\n",
    "- Multi-level directory of text files\n",
    "\n",
    "In this notebook we will specify the format requirements of each of these data formats and how to import them into MuSE.\n",
    "\n",
    "All implemented data loaders can be found in the `muse.data_importer` module, and follow the same format, of being initialized with some options to specify the specific format.\n",
    "\n",
    "Typically, you will only interact with these through the `Muse` class, however, the data loaders can be used independently if needed."
   ],
   "id": "494c989d8b785eab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Basic API\n",
    "\n",
    "Below is the API for loading data into MuSE:\n",
    "```python\n",
    "from muse import Muse\n",
    "\n",
    "muse = Muse()\n",
    "\n",
    "# Returns nothing, only sets the data in the Muse object\n",
    "muse.set_data(\"data type\", \"path/to/data\", \"language\", {\"additional\": \"options\"})\n",
    "```\n",
    "\n",
    "Similarly, using the data loaders directly:\n",
    "```python\n",
    "from muse.data_importer import import_data\n",
    "\n",
    "# Returns the loaded data: Union[list[Document], list[MultiDocument], list[Conversation]]\n",
    "import_data(\"data type\", \"path/to/data\", \"language\", {\"additional\": \"options\"})\n",
    "```\n",
    "\n",
    "The options are specific to the data loader, and will be detailed in the following sections, any options which are not expected by the data loader being applied will be ignored, e.g. if you set `csv_separator` for a Parquet file, or directory it will be ignored."
   ],
   "id": "c3f5ccc5f1adb1c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data for Demonstration",
   "id": "f3dea10e858e7cf3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T08:16:19.483214Z",
     "start_time": "2024-10-03T08:16:19.474835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "document = \"This is a document. It has multiple sentences. It is used to test the data importers.\"\n",
    "additional_document = \"This is an additional document. It has multiple sentences. It is used to test the data importers.\"\n",
    "conversation = \"#Speaker1# This is a conversation turn. #Speaker2# This is another conversation turn.\"\n",
    "summary = \"This is a summary of the document. It is used to test the data importers.\"\n",
    "metadata = {\"metadata1\": \"This is metadata1\", \"metadata2\": \"This is metadata2\"}"
   ],
   "id": "4851192a800ec3aa",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## CSV\n",
    "\n",
    "CSV files are commonly used in Document, and Multi-Document Summarization datasets, and other formats can often be easily converted to CSV. \n",
    "\n",
    "Currently, MuSE can only take a single CSV file as input.\n",
    "This is loaded by the `ColumnarConnector` class, which takes in the initializer the following options:\n",
    "- `text_column`: This is the name of the column in the CSV file that contains the text data for the document, documents, or conversation. It defaults to `text`.\n",
    "- `summary_column`: This is the name of the column in the CSV file that contains the summary data for the document, documents, or conversation. It defaults to `summary`. This is optional, and if not provided, the dataset will be assumed to be missing summaries, which may be required for some evaluation metrics.\n",
    "- `metadata_columns`: This is a list of column names in the CSV file that contain metadata for the document, documents, or conversation. It defaults to an empty list `[]`, in which case, all extra columns will be assumed to be metadata, and loaded with the data. This metadata is currently not used by MuSE, but may be useful for future features, or for custom use cases.\n",
    "- `csv_separator`: This is the separator used in the CSV file. It defaults to `,`.\n",
    "- `multi_doc_id_column`: This is the name of the column in the CSV file that contains the document id for multi-document datasets. It defaults to `multi_doc_id`. This is optional, and if not provided, and you are loading a multi-document dataset, the documents will be assumed to be all loaded in the same row, separated by a delimiter.\n",
    "- `multi_document_delimiter`: In the case you are not using a `multi_doc_id_column`, this is the delimiter used to separate the documents in the same row. It defaults to `#DOCUMENT#`, and will be used to split the documents into separate documents.\n",
    "- `conversation_separator`: This is the separator used to separate the conversation turns in the CSV file. It is a regex pattern, and defaults to `\"#\\w+#\"`. such that the name of the speaker is defined within the `#` characters. If you provide your own, it must have one group, which will be used to split the conversation turns."
   ],
   "id": "908088a01cf28e89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from muse import Muse, DataType\n",
    "\n",
    "# Prepare a basic CSV file for demonstration\n",
    "with TemporaryDirectory() as tmpdir:\n",
    "    print(\"Basic single document CSV file:\")\n",
    "    csv_path = Path(f\"{tmpdir}/test.csv\")\n",
    "    df = pd.DataFrame({\"text\": [document, additional_document], \"summary\": [summary, summary], **metadata})\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    # We need a Muse object to load the data\n",
    "    muse = Muse()\n",
    "\n",
    "    # Load the data\n",
    "    muse.set_data(DataType.SingleDocument, str(csv_path), 'en')\n",
    "\n",
    "    for doc in muse.data:\n",
    "        print(doc.text)\n",
    "        print(doc.summary)\n",
    "        print(doc.metadata)\n",
    "        print()\n",
    "\n",
    "    print(\"=\" * 20)\n",
    "\n",
    "# Custom column names, and only metadata1\n",
    "with TemporaryDirectory() as tmpdir:\n",
    "    print(\"custom column names, and only metadata1 single document CSV file:\")\n",
    "    csv_path = Path(f\"{tmpdir}/test.csv\")\n",
    "    df = pd.DataFrame(\n",
    "        {\"text_with_new_name\": [document, additional_document], \"summary_with_new_name\": [summary, summary],\n",
    "         **metadata})\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    # We need a Muse object to load the data\n",
    "    muse = Muse()\n",
    "\n",
    "    # Load the data\n",
    "    muse.set_data(DataType.SingleDocument, str(csv_path), 'en',\n",
    "                  {\"text_column\": \"text_with_new_name\", \"summary_column\": \"summary_with_new_name\",\n",
    "                   \"metadata_columns\": [\"metadata1\"]})\n",
    "\n",
    "    for doc in muse.data:\n",
    "        print(doc.text)\n",
    "        print(doc.summary)\n",
    "        print(doc.metadata)\n",
    "        print()\n",
    "\n",
    "    print(\"=\" * 20)\n",
    "\n",
    "# Multi-document CSV file\n",
    "with TemporaryDirectory() as tmpdir:\n",
    "    print(\"Multi-document CSV file:\")\n",
    "    csv_path = Path(f\"{tmpdir}/test.csv\")\n",
    "    # As you can see here, when using `multi_doc_id_column`, if a summary is provided, you only need to provide it once, and it will be assumed to be the same for all documents in the multi-document group.\n",
    "    df = pd.DataFrame(\n",
    "        {\"text\": [document, additional_document], \"summary\": [summary, None], \"multi_doc_id\": [\"doc1\", \"doc1\"],\n",
    "         **metadata})\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    # We need a Muse object to load the data\n",
    "    muse = Muse()\n",
    "\n",
    "    # Load the data\n",
    "    muse.set_data(DataType.MultiDocument, str(csv_path), 'en')\n",
    "\n",
    "    for multi_doc in muse.data:\n",
    "        for doc in multi_doc.documents:\n",
    "            print(doc.text)\n",
    "            print(\"-\" * 5)\n",
    "        print(multi_doc.summary)\n",
    "        print(multi_doc.metadata)\n",
    "        print()\n",
    "\n",
    "    print(\"=\" * 20)\n",
    "\n",
    "# Multi-document CSV file with delimiter\n",
    "with TemporaryDirectory() as tmpdir:\n",
    "    print(\"Multi-document CSV file with delimiter:\")\n",
    "    csv_path = Path(f\"{tmpdir}/test.csv\")\n",
    "    df = pd.DataFrame({\"text\": [f\"{document}###{additional_document}\"], \"summary\": [summary], **metadata})\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    # We need a Muse object to load the data\n",
    "    muse = Muse()\n",
    "\n",
    "    # Load the data, here we specify the delimiter used to separate is `###` rather than the default `#DOCUMENT#`\n",
    "    muse.set_data(DataType.MultiDocument, str(csv_path), 'en', {\"multi_document_delimiter\": \"###\"})\n",
    "\n",
    "    for multi_doc in muse.data:\n",
    "        for doc in multi_doc.documents:\n",
    "            print(doc.text)\n",
    "            print(\"-\" * 5)\n",
    "        print(multi_doc.summary)\n",
    "        print(multi_doc.metadata)\n",
    "        print()\n",
    "\n",
    "    print(\"=\" * 20)\n",
    "\n",
    "# Conversation CSV file with custom separator\n",
    "with TemporaryDirectory() as tmpdir:\n",
    "    print(\"Conversation CSV file with custom separator:\")\n",
    "    csv_path = Path(f\"{tmpdir}/test.csv\")\n",
    "    df = pd.DataFrame({\"text\": [conversation.replace(\"#Speaker\", \"#Speaker \")], **metadata})\n",
    "    df.to_csv(csv_path, index=False, sep=\";\")\n",
    "\n",
    "    # We need a Muse object to load the data\n",
    "    muse = Muse()\n",
    "\n",
    "    # Load the data, here we specify the separator used to separate the conversation turns is `#Speaker\\d+#`\n",
    "    muse.set_data(DataType.Conversation, str(csv_path), 'en',\n",
    "                  {\"conversation_separator\": \"#Speaker \\d+#\", \"csv_separator\": \";\"})\n",
    "\n",
    "    for conv in muse.data:\n",
    "        for turn in conv.text_units:\n",
    "            print(f\"{turn.speaker}: {turn.text}\")\n",
    "        print(conv.metadata)\n",
    "        print()\n",
    "\n",
    "    print(\"=\" * 20)"
   ],
   "id": "59376383c737c34d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parquet\n",
    "\n",
    "Parquet files are a columnar storage format, and as such share many similarities with CSV files, only differing within MuSE, in that the `csv_separator` option is not available, as it is not needed."
   ],
   "id": "f092ed48e2547308"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from muse import Muse\n",
    "\n",
    "# Simple Parquet file example\n",
    "with TemporaryDirectory() as tmpdir:\n",
    "    print(\"Simple Parquet file:\")\n",
    "    parquet_path = Path(f\"{tmpdir}/test.parquet\")\n",
    "    df = pd.DataFrame({\"text\": [document, additional_document], \"summary\": [summary, summary], **metadata})\n",
    "    df.to_parquet(parquet_path, index=False)\n",
    "\n",
    "    # We need a Muse object to load the data\n",
    "    muse = Muse()\n",
    "\n",
    "    # Load the data\n",
    "    muse.set_data(\"document\", str(parquet_path), 'en')\n",
    "\n",
    "    for doc in muse.data:\n",
    "        print(doc.text)\n",
    "        print(doc.summary)\n",
    "        print(doc.metadata)\n",
    "        print()\n",
    "\n",
    "    print(\"=\" * 20)"
   ],
   "id": "1fdaa610cb38a243",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Directories and Multi-level Directories\n",
    "\n",
    "Another format we support is a directory structure, where each file represents a document, documents, or conversation.\n",
    "As with the previous formats, to represent multi-document datasets, you can either use delimiter within the file, or use multiple files within a directory. \n",
    "For conversations, you will also use a delimiter within the file.\n",
    "\n",
    "We provide two further groups options for directories:\n",
    "- `summary_suffix`: This is the suffix used to identify the summary file for a document, documents, or conversation. It defaults to `_summary`, and will be applied to single level directories.\n",
    "- `metadata_suffix`: This is the suffix used to identify the metadata file for a document, documents, or conversation. It defaults to `_metadata`, and will be applied to single level directories.\n",
    "- `summary_file`: This is the name of the file used to identify the summary file for a document, documents, or conversation. It defaults to `summary`. This is used for multi-level directories.\n",
    "- `metadata_file`: This is the name of the file used to identify the metadata file for a document, documents, or conversation. It defaults to `metadata`. This is used for multi-level directories."
   ],
   "id": "31cae56a61f22990"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from muse import Muse\n",
    "\n",
    "# Single level directory\n",
    "with TemporaryDirectory() as tmpdir:\n",
    "    print(\"Single level directory:\")\n",
    "    with open(f\"{tmpdir}/doc1.txt\", \"w\") as f:\n",
    "        f.write(document)\n",
    "    with open(f\"{tmpdir}/doc1_summary_special_name.txt\", \"w\") as f:\n",
    "        f.write(summary)\n",
    "    with open(f\"{tmpdir}/doc1_metadata_special_name.txt\", \"w\") as f:\n",
    "        f.write(str(metadata))\n",
    "    with open(f\"{tmpdir}/doc2.txt\", \"w\") as f:\n",
    "        f.write(additional_document)\n",
    "    with open(f\"{tmpdir}/doc2_summary_special_name.txt\", \"w\") as f:\n",
    "        f.write(summary)\n",
    "    with open(f\"{tmpdir}/doc2_metadata_special_name.txt\", \"w\") as f:\n",
    "        f.write(str(metadata))\n",
    "\n",
    "    # We need a Muse object to load the data\n",
    "    muse = Muse()\n",
    "\n",
    "    # Load the data\n",
    "    muse.set_data(\"document\", tmpdir, 'en',\n",
    "                  {\"summary_suffix\": \"_summary_special_name\", \"metadata_suffix\": \"_metadata_special_name\"})\n",
    "\n",
    "    for doc in muse.data:\n",
    "        print(doc.text)\n",
    "        print(doc.summary)\n",
    "        print(doc.metadata)\n",
    "        print()\n",
    "\n",
    "    print(\"=\" * 20)\n",
    "\n",
    "# Multi-level directory\n",
    "with TemporaryDirectory() as tmpdir:\n",
    "    print(\"Multi-level directory:\")\n",
    "    os.mkdir(f\"{tmpdir}/doc1\")\n",
    "    os.mkdir(f\"{tmpdir}/doc2\")\n",
    "\n",
    "    with open(f\"{tmpdir}/doc1/doc1.txt\", \"w\") as f:\n",
    "        f.write(document)\n",
    "    with open(f\"{tmpdir}/doc1/doc2.txt\", \"w\") as f:\n",
    "        f.write(additional_document)\n",
    "    with open(f\"{tmpdir}/doc1/summary_special_name.txt\", \"w\") as f:\n",
    "        f.write(summary)\n",
    "    with open(f\"{tmpdir}/doc1/metadata_special_name.txt\", \"w\") as f:\n",
    "        f.write(str(metadata))\n",
    "    with open(f\"{tmpdir}/doc2/doc2.txt\", \"w\") as f:\n",
    "        f.write(additional_document)\n",
    "    with open(f\"{tmpdir}/doc2/summary_special_name.txt\", \"w\") as f:\n",
    "        f.write(summary)\n",
    "    with open(f\"{tmpdir}/doc2/metadata_special_name.txt\", \"w\") as f:\n",
    "        f.write(str(metadata))\n",
    "\n",
    "    # We need a Muse object to load the data\n",
    "    muse = Muse()\n",
    "\n",
    "    # Load the data\n",
    "    muse.set_data(\"multi-document\", tmpdir, 'en',\n",
    "                  {\"summary_file\": \"summary_special_name\", \"metadata_file\": \"metadata_special_name\"})\n",
    "\n",
    "    for multi_doc in muse.data:\n",
    "        for doc in multi_doc.documents:\n",
    "            print(doc.text)\n",
    "            print(\"-\" * 5)\n",
    "        print(multi_doc.summary)\n",
    "        print(multi_doc.metadata)\n",
    "        print()\n",
    "\n",
    "    print(\"=\" * 20)"
   ],
   "id": "3a643a306295d718",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Source-Target files\n",
    "\n",
    "To be completed."
   ],
   "id": "7b81ff03d815298b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Accessing Datasets\n",
    "\n",
    "MuSE also provides some datasets for demonstration purposes, these must be downloaded before use, we can either do this with the `muse_fetch` command line tool, or by using the `fetch_datasets` function from the `muse.utils` module."
   ],
   "id": "f7f1b78b595e0b40"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
